{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunilypatil/starter-slapp-app/blob/master/Word_details.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYGmdbiv3kay",
        "outputId": "3dc98695-9088-4db1-96e7-de17f2b9d1a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting airtable-python-wrapper\n",
            "  Downloading airtable_python_wrapper-0.15.3-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from airtable-python-wrapper) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->airtable-python-wrapper) (2023.7.22)\n",
            "Installing collected packages: airtable-python-wrapper\n",
            "Successfully installed airtable-python-wrapper-0.15.3\n",
            "Collecting pyairtable\n",
            "  Downloading pyairtable-2.1.0.post1-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m974.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflection (from pyairtable)\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from pyairtable) (2.2.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pyairtable) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyairtable) (4.7.1)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from pyairtable) (2.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pyairtable) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pyairtable) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pyairtable) (2023.7.22)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->pyairtable) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->pyairtable) (2.6.0)\n",
            "Installing collected packages: inflection, pyairtable\n",
            "Successfully installed inflection-0.5.1 pyairtable-2.1.0.post1\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.9-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.9\n"
          ]
        }
      ],
      "source": [
        "!pip install airtable-python-wrapper\n",
        "!pip install pyairtable\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "JeP1WDMu-VVI",
        "outputId": "1a4a70c9-aa47-4f7c-ccf8-454f235e78ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7d9d02ae2cb2>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'difficulty'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fields'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fields'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'difficulty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mword_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_word_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         response = openai.ChatCompletion.create(\n",
            "\u001b[0;32m<ipython-input-9-7d9d02ae2cb2>\u001b[0m in \u001b[0;36mfetch_word_details\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     42\u001b[0m     }\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-BpLr9***************************************CN9U. You can find your API key at https://platform.openai.com/account/api-keys."
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import openai\n",
        "from airtable import Airtable\n",
        "\n",
        "# Setup\n",
        "OPENAI_API_KEY = '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'  # placeholder\n",
        "AIRTABLE_BASE_ID = 'app3bXV2qSbzN9HdT'  # placeholder\n",
        "AIRTABLE_API_KEY = 'keyFISaeSAkBbs49T'  # placeholder\n",
        "WORD_TABLE_NAME = 'tblW04oGjQn1h8alE'  # placeholder\n",
        "\n",
        "# Initialization\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "airtable_words = Airtable(AIRTABLE_BASE_ID, WORD_TABLE_NAME, api_key=AIRTABLE_API_KEY)\n",
        "airtable_themes = Airtable(AIRTABLE_BASE_ID, 'theme', api_key=AIRTABLE_API_KEY)\n",
        "airtable_sub_themes = Airtable(AIRTABLE_BASE_ID, 'sub_theme', api_key=AIRTABLE_API_KEY)\n",
        "\n",
        "# Fetch themes and sub-themes from Airtable\n",
        "themes_data = {}\n",
        "all_themes = airtable_themes.get_all()\n",
        "all_sub_themes = airtable_sub_themes.get_all()\n",
        "\n",
        "\n",
        "for theme_record in all_themes:\n",
        "    theme_name = theme_record['fields']['theme']\n",
        "    themes_data[theme_name] = []\n",
        "\n",
        "for sub_theme_record in all_sub_themes:\n",
        "    sub_theme_name = sub_theme_record['fields']['sub_theme']\n",
        "    associated_theme = sub_theme_record['fields']['theme'][0]  # Assuming single linked theme\n",
        "    theme_name = [rec for rec in all_themes if rec['id'] == associated_theme][0]['fields']['theme']\n",
        "    themes_data[theme_name].append(sub_theme_name)\n",
        "\n",
        "def fetch_word_details(word):\n",
        "    details = {}\n",
        "    prompts = {\n",
        "        'definition': f\"Define the word {word}. A maximum of 10 words only.\",\n",
        "        'usage': f\"Provide a sentence using the word {word}. A maximum of 10 words only.\",\n",
        "        'synonyms': f\"List synonyms for the word {word}. Only the words and not why they are synonyms for the word. Comma seperated no bullets\",\n",
        "        'antonyms': f\"List antonyms for the word {word}. Only the words and not why they are antonyms for the word. Comma seperated no bullets\",\n",
        "        'difficulty': f'''Rate the difficulty of the word {word} on a scale of easy, medium and hard\n",
        "        as applicable to a 10 year old child. Please respond as one of the three difficulties and nothing else'''\n",
        "    }\n",
        "    for key, prompt in prompts.items():\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": '''You are the world's leading English teacher helping 9-10\n",
        "                year old children, preparing for the 11+ exams to build their vocabulary.\n",
        "                Remember, the definition, usage need to be context aware of the worldview of a 10 year old child'''},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        details[key] = response.choices[0]['message']['content'].strip()\n",
        "    return details\n",
        "\n",
        "def get_words_between_ids(start_id, end_id, words_data):\n",
        "    # Filter words based on the given range of IDs\n",
        "    filtered_words = [word for word in words_data if start_id <= int(word['fields']['id']) <= end_id]\n",
        "    # Sort the filtered words based on the 'id' in ascending order\n",
        "    sorted_words = sorted(filtered_words, key=lambda x: int(x['fields']['id']))\n",
        "    return sorted_words\n",
        "\n",
        "start_id = 1144\n",
        "end_id = 1200\n",
        "\n",
        "# Cache: Fetch all the words once and store in memory\n",
        "all_words_data = airtable_words.get_all()\n",
        "\n",
        "\n",
        "for record in get_words_between_ids(start_id, end_id, all_words_data):\n",
        "    word = record['fields']['word']\n",
        "\n",
        "    # Only fetch and process word details if the 'difficulty' field is empty\n",
        "    if 'difficulty' not in record['fields'] or not record['fields']['difficulty'].strip():\n",
        "\n",
        "        word_details = fetch_word_details(word)\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are the world's leading  English teacher helping 9-10 year old children, preparing for the 11+ exams to build their vocabulary. I understand the nuances of 50000+ commonly used English words and can easiky and accurately classify words into themes and subthemes\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Which theme and sub-theme best matches the word '{word}' from the following options? {themes_data}\"}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        suggested_classification = response.choices[0]['message']['content'].strip().lower()\n",
        "\n",
        "        selected_theme = None\n",
        "        selected_sub_theme = None\n",
        "\n",
        "        # Check ChatGPT's response against available themes and sub-themes\n",
        "        for theme, sub_themes in themes_data.items():\n",
        "            if theme.lower() in suggested_classification:\n",
        "                selected_theme = theme\n",
        "            for sub_theme in sub_themes:\n",
        "                if sub_theme.lower() in suggested_classification:\n",
        "                    selected_sub_theme = sub_theme\n",
        "                    break\n",
        "            if selected_theme and selected_sub_theme:\n",
        "                break\n",
        "\n",
        "\n",
        "        # If the selected_theme doesn't exist in the theme table, add it\n",
        "        if selected_theme:\n",
        "            if not any(theme['fields']['theme'].strip().lower() == selected_theme.strip().lower() for theme in all_themes):\n",
        "                airtable_themes.create({'theme': selected_theme})\n",
        "                # Fetch updated themes list\n",
        "                all_themes = airtable_themes.get_all()\n",
        "\n",
        "            # Get the theme_id for the selected_theme\n",
        "            theme_id = [rec['id'] for rec in all_themes if rec['fields']['theme'].strip().lower() == selected_theme.strip().lower()][0]\n",
        "        else:\n",
        "            theme_id = None\n",
        "\n",
        "        # If the selected_sub_theme doesn't exist in the sub_theme table, add it and link to its theme\n",
        "        if selected_sub_theme:\n",
        "            if not any('sub_theme' in rec['fields'] and rec['fields']['sub_theme'].strip().lower() == selected_sub_theme.strip().lower() for rec in all_sub_themes):\n",
        "                airtable_sub_themes.create({'sub_theme': selected_sub_theme, 'theme': [theme_id]})\n",
        "                # Fetch updated sub-themes list\n",
        "                all_sub_themes = airtable_sub_themes.get_all()\n",
        "\n",
        "            # Get the sub_theme_id for the selected_sub_theme\n",
        "            sub_theme_id = [rec['id'] for rec in all_sub_themes if 'sub_theme' in rec['fields'] and rec['fields']['sub_theme'].strip().lower() == selected_sub_theme.strip().lower()][0]\n",
        "        else:\n",
        "            sub_theme_id = None\n",
        "\n",
        "\n",
        "        # Construct data for updating the word's record\n",
        "\n",
        "        if theme_id is None or sub_theme_id is None:\n",
        "            print(f\"Error updating word: {word}.\")\n",
        "            if theme_id is None:\n",
        "                print(f\"Theme ID for {selected_theme} is missing.\")\n",
        "            if sub_theme_id is None:\n",
        "                print(f\"Sub-theme ID for {selected_sub_theme} is missing.\")\n",
        "        else:\n",
        "            data = {\n",
        "                  **word_details\n",
        "            }\n",
        "\n",
        "            # Only add theme_id and sub_theme_id if they're not None\n",
        "            if theme_id:\n",
        "                data['theme'] = [theme_id]\n",
        "            if sub_theme_id:\n",
        "                data['sub_theme'] = [sub_theme_id]\n",
        "\n",
        "            print(data)\n",
        "\n",
        "            airtable_words.update(record['id'], data)\n",
        "\n",
        "        # Update the cached word data in memory after processing\n",
        "        record['fields'].update(word_details)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}